# CaptionGen
CaptionGen enhances AI-powered image captioning with its ability to generate emotionally attuned text, its facility for translations across languages, and its enriched contextual descriptions drawn from the latest in NLP and machine learning advancements.

In a world brimming with visual narratives, each image harbors its own untold story. The CaptionGen project taps into this richness, using CLIP, GPT-2 and GPT-3.5 to infuse AI-generated image captions with emotional depth, resonating with a diverse array of user preferences and languages. This endeavor bridges the gap between mere image description and deeper user connection. CaptionGen enriches captioning with tone customization, multilingual translation, and information enrichment, subtly transforming the interaction between AI, images, and the viewer into a more engaging and intuitive experience.

References:
Sources
ClipCap: CLIP Prefix for Image Captioning by Ron Mokady, Amir Hertz, Amit H. Bermano

Github links:

https://github.com/rmokady/CLIP_prefix_caption

https://github.com/openai/CLIP

https://github.com/LAION-AI/General-GPT

https://github.com/jmisilo/clip-gpt-captioning

https://github.com/Ankuraxz/Image-Caption-Generator


